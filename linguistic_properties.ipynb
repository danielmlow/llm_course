{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595ffbee",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](htt`ps://colab.research.google.com/github/danielmlow/llm_course/blob/main/linguistic_properties.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b19f1d",
   "metadata": {},
   "source": [
    "# English linguistic features with spaCy + TextDescriptives\n",
    "\n",
    "This tutorial shows how to extract a wide set of linguistic and readability features from English text using spaCy and the TextDescriptives library (https://github.com/HLasse/TextDescriptives).\n",
    "\n",
    "Sections:\n",
    "- Install dependencies and download a spaCy model\n",
    "- Extract features using the TextDescriptives convenience functions\n",
    "- Integrate TextDescriptives as a spaCy pipeline component and access extensions on `Doc` objects\n",
    "- Run metrics on a list of texts and export to a DataFrame\n",
    "\n",
    "Notes:\n",
    "- This notebook uses `textdescriptives` v2+ API. See the project README and docs for a full list of metrics and components. https://hlasse.github.io/TextDescriptives/usingthepackage.html#available-attributes \n",
    "- If you already have `spacy` and `en_core_web_sm` (or another English model) installed, skip the install cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15dc2c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textdescriptives\n",
      "  Downloading textdescriptives-2.8.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting numpy<2.0.0,>=1.20.0 (from textdescriptives)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from textdescriptives) (2.3.2)\n",
      "Collecting pyphen>=0.11.0 (from textdescriptives)\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting ftfy>=6.0.3 (from textdescriptives)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting numpy<2.0.0,>=1.20.0 (from textdescriptives)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from textdescriptives) (2.3.2)\n",
      "Collecting pyphen>=0.11.0 (from textdescriptives)\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting ftfy>=6.0.3 (from textdescriptives)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from textdescriptives) (2.11.9)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from textdescriptives) (2.11.9)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: jinja2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: jinja2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pydantic>=2.0->textdescriptives) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pydantic>=2.0->textdescriptives) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pydantic>=2.0->textdescriptives) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pydantic>=2.0->textdescriptives) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pydantic>=2.0->textdescriptives) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pydantic>=2.0->textdescriptives) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pydantic>=2.0->textdescriptives) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pydantic>=2.0->textdescriptives) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from ftfy>=6.0.3->textdescriptives) (0.2.13)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pandas>=1.0.0->textdescriptives) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pandas>=1.0.0->textdescriptives) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pandas>=1.0.0->textdescriptives) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->textdescriptives) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from ftfy>=6.0.3->textdescriptives) (0.2.13)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pandas>=1.0.0->textdescriptives) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pandas>=1.0.0->textdescriptives) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from pandas>=1.0.0->textdescriptives) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->textdescriptives) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting spacy_lookups_data<1.1.0,>=1.0.3 (from spacy[lookups]>=3.6.0->textdescriptives)\n",
      "  Downloading spacy_lookups_data-1.0.5-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading textdescriptives-2.8.4-py3-none-any.whl (254 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl (6.4 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting spacy_lookups_data<1.1.0,>=1.0.3 (from spacy[lookups]>=3.6.0->textdescriptives)\n",
      "  Downloading spacy_lookups_data-1.0.5-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading textdescriptives-2.8.4-py3-none-any.whl (254 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.10-cp311-cp311-macosx_11_0_arm64.whl (127 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (634 kB)\n",
      "Using cached thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl (774 kB)\n",
      "Downloading blis-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.22.0-py3-none-any.whl (61 kB)\n",
      "Downloading smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Downloading marisa_trie-1.3.1-cp311-cp311-macosx_11_0_arm64.whl (158 kB)\n",
      "Downloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.10-cp311-cp311-macosx_11_0_arm64.whl (127 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (634 kB)\n",
      "Using cached thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl (774 kB)\n",
      "Downloading blis-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.22.0-py3-none-any.whl (61 kB)\n",
      "Downloading smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Downloading marisa_trie-1.3.1-cp311-cp311-macosx_11_0_arm64.whl (158 kB)\n",
      "Downloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading spacy_lookups_data-1.0.5-py2.py3-none-any.whl (98.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading spacy_lookups_data-1.0.5-py2.py3-none-any.whl (98.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.3-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.3-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy_lookups_data, spacy-loggers, spacy-legacy, shellingham, pyphen, numpy, murmurhash, mdurl, marisa-trie, ftfy, cloudpathlib, catalogue, srsly, smart-open, preshed, markdown-it-py, language-data, blis, rich, langcodes, confection, typer, thinc, weasel, spacy, textdescriptives\n",
      "\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/29\u001b[0m [spacy_lookups_data]Installing collected packages: cymem, wrapt, wasabi, spacy_lookups_data, spacy-loggers, spacy-legacy, shellingham, pyphen, numpy, murmurhash, mdurl, marisa-trie, ftfy, cloudpathlib, catalogue, srsly, smart-open, preshed, markdown-it-py, language-data, blis, rich, langcodes, confection, typer, thinc, weasel, spacy, textdescriptives\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [pyphen]ookups_data]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [pyphen]\n",
      "\u001b[2K    Uninstalling numpy-2.3.3:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [pyphen]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [pyphen]\n",
      "\u001b[2K    Uninstalling numpy-2.3.3:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [textdescriptives][spacy]des]ata]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blis-1.2.1 catalogue-2.0.10 cloudpathlib-0.22.0 confection-0.1.5 cymem-2.0.11 ftfy-6.3.1 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 markdown-it-py-4.0.0 mdurl-0.1.2 murmurhash-1.0.13 numpy-1.26.4 preshed-3.0.10 pyphen-0.17.2 rich-14.1.0 shellingham-1.5.4 smart-open-7.3.1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 spacy_lookups_data-1.0.5 srsly-2.5.1 textdescriptives-2.8.4 thinc-8.3.4 typer-0.19.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.3\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [textdescriptives][spacy]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blis-1.2.1 catalogue-2.0.10 cloudpathlib-0.22.0 confection-0.1.5 cymem-2.0.11 ftfy-6.3.1 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 markdown-it-py-4.0.0 mdurl-0.1.2 murmurhash-1.0.13 numpy-1.26.4 preshed-3.0.10 pyphen-0.17.2 rich-14.1.0 shellingham-1.5.4 smart-open-7.3.1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 spacy_lookups_data-1.0.5 srsly-2.5.1 textdescriptives-2.8.4 thinc-8.3.4 typer-0.19.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.3\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mCollecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Installed textdescriptives and spacy + downloaded en_core_web_sm\n",
      "Installed textdescriptives and spacy + downloaded en_core_web_sm\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once).\n",
    "# If you prefer to install manually in your environment, skip this cell.\n",
    "import sys\n",
    "import subprocess\n",
    "packages = [\n",
    "    \"textdescriptives\",\n",
    "    \"spacy\"\n",
    "]\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade'] + packages)\n",
    "# download a small English model (change to en_core_web_lg if you want larger vectors)\n",
    "subprocess.check_call([sys.executable, '-m', 'spacy', 'download', 'en_core_web_sm'])\n",
    "print('Installed textdescriptives and spacy + downloaded en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2cc77",
   "metadata": {},
   "source": [
    "## Quick example: extract metrics from a single text using `td.extract_metrics`\n",
    "`td.extract_metrics` is a convenience function that will auto-download an appropriate spaCy model if needed and return a pandas DataFrame with the requested metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ No spacy model provided. Inferring spacy model for en.\u001b[0m\n",
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mCollecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Successfully installed en-core-web-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>The world is changed. I feel it in the water. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passed_quality_check</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_stop_words</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_ratio</th>\n",
       "      <td>0.853659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_word_length</th>\n",
       "      <td>2.95122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rix</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependency_distance_mean</th>\n",
       "      <td>1.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependency_distance_std</th>\n",
       "      <td>0.530263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop_adjacent_dependency_relation_mean</th>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop_adjacent_dependency_relation_std</th>\n",
       "      <td>0.072281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        0\n",
       "text                                    The world is changed. I feel it in the water. ...\n",
       "passed_quality_check                                                                False\n",
       "n_stop_words                                                                         24.0\n",
       "alpha_ratio                                                                      0.853659\n",
       "mean_word_length                                                                  2.95122\n",
       "...                                                                                   ...\n",
       "rix                                                                                   0.4\n",
       "dependency_distance_mean                                                         1.761905\n",
       "dependency_distance_std                                                          0.530263\n",
       "prop_adjacent_dependency_relation_mean                                           0.457143\n",
       "prop_adjacent_dependency_relation_std                                            0.072281\n",
       "\n",
       "[70 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textdescriptives as td\n",
    "\n",
    "text = (\n",
    "    'The world is changed. I feel it in the water. I feel it in the earth. '\n",
    "    'I smell it in the air. Much that once was is lost, for none now live who remember it.'\n",
    ")\n",
    "# extract all metrics (can be large). Use metrics=['readability','pos_proportions'] to get a subset.\n",
    "df_all = td.extract_metrics(text=text, lang='en', metrics=None)\n",
    "\n",
    "df_all.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ec6c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'passed_quality_check', 'n_stop_words', 'alpha_ratio',\n",
      "       'mean_word_length', 'doc_length', 'symbol_to_word_ratio_#',\n",
      "       'proportion_ellipsis', 'proportion_bullet_points',\n",
      "       'contains_lorem ipsum', 'duplicate_line_chr_fraction',\n",
      "       'duplicate_paragraph_chr_fraction', 'duplicate_ngram_chr_fraction_5',\n",
      "       'duplicate_ngram_chr_fraction_6', 'duplicate_ngram_chr_fraction_7',\n",
      "       'duplicate_ngram_chr_fraction_8', 'duplicate_ngram_chr_fraction_9',\n",
      "       'duplicate_ngram_chr_fraction_10', 'top_ngram_chr_fraction_2',\n",
      "       'top_ngram_chr_fraction_3', 'top_ngram_chr_fraction_4', 'oov_ratio',\n",
      "       'first_order_coherence', 'second_order_coherence', 'entropy',\n",
      "       'perplexity', 'per_word_perplexity', 'pos_prop_ADJ', 'pos_prop_ADP',\n",
      "       'pos_prop_ADV', 'pos_prop_AUX', 'pos_prop_CCONJ', 'pos_prop_DET',\n",
      "       'pos_prop_INTJ', 'pos_prop_NOUN', 'pos_prop_NUM', 'pos_prop_PART',\n",
      "       'pos_prop_PRON', 'pos_prop_PROPN', 'pos_prop_PUNCT', 'pos_prop_SCONJ',\n",
      "       'pos_prop_SYM', 'pos_prop_VERB', 'pos_prop_X', 'token_length_mean',\n",
      "       'token_length_median', 'token_length_std', 'sentence_length_mean',\n",
      "       'sentence_length_median', 'sentence_length_std',\n",
      "       'syllables_per_token_mean', 'syllables_per_token_median',\n",
      "       'syllables_per_token_std', 'n_tokens', 'n_unique_tokens',\n",
      "       'proportion_unique_tokens', 'n_characters', 'n_sentences',\n",
      "       'flesch_reading_ease', 'flesch_kincaid_grade', 'smog', 'gunning_fog',\n",
      "       'automated_readability_index', 'coleman_liau_index', 'lix', 'rix',\n",
      "       'dependency_distance_mean', 'dependency_distance_std',\n",
      "       'prop_adjacent_dependency_relation_mean',\n",
      "       'prop_adjacent_dependency_relation_std'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_all = df_all.T\n",
    "print(df_all.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0f20e",
   "metadata": {},
   "source": [
    "## Integrate TextDescriptives into a spaCy pipeline\n",
    "You can add `textdescriptives` components to any spaCy `nlp` pipeline. Components are named `textdescriptives/<component>` or use the shorthand `textdescriptives/all` to add all components. After adding, results are available on the `doc._.` extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9accad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readability metrics (doc._.readability):\n",
      "{'flesch_reading_ease': 107.87857142857146, 'flesch_kincaid_grade': -0.048571428571428044, 'smog': 5.683917801722854, 'gunning_fog': 3.942857142857143, 'automated_readability_index': -2.4542857142857173, 'coleman_liau_index': -0.7085714285714317, 'lix': 12.714285714285715, 'rix': 0.4}\n",
      "Some basic descriptive stats from doc._.descriptive_stats keys:\n",
      "{'n_tokens': 35, 'n_sentences': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielmlow/miniconda3/envs/llm_course/lib/python3.11/site-packages/textdescriptives/components/coherence.py:44: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarities.append(sent.similarity(sents[i + order]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>The world is changed. I feel it in the water. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passed_quality_check</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_stop_words</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_ratio</th>\n",
       "      <td>0.853659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_word_length</th>\n",
       "      <td>2.95122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      0\n",
       "text                  The world is changed. I feel it in the water. ...\n",
       "passed_quality_check                                              False\n",
       "n_stop_words                                                       24.0\n",
       "alpha_ratio                                                    0.853659\n",
       "mean_word_length                                                2.95122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import textdescriptives as td\n",
    "import pandas as pd\n",
    "\n",
    "# load a spaCy model (use en_core_web_sm or en_core_web_lg)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# add all textdescriptives components to the pipeline\n",
    "nlp.add_pipe('textdescriptives/all')\n",
    "\n",
    "doc = nlp(text)\n",
    "# print some of the attributes produced by TextDescriptives\n",
    "print('Readability metrics (doc._.readability):')\n",
    "print(doc._.readability)\n",
    "print('Some basic descriptive stats from doc._.descriptive_stats keys:')\n",
    "print({k: v for k, v in doc._.descriptive_stats.items() if k in ['n_tokens','n_sentences','mean_word_length']})\n",
    "\n",
    "# convert the doc to a DataFrame (single-row)\n",
    "df_from_doc = td.extract_df(doc)\n",
    "df_from_doc.T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa37390",
   "metadata": {},
   "source": [
    "## Inspect spaCy-side features alongside TextDescriptives outputs\n",
    "You can still access token-level spaCy data like `.pos_`, `.dep_`, `.lemma_`, etc. below we show tokens and a few token-level metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa398710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>auxpass</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>changed</td>\n",
       "      <td>change</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feel</td>\n",
       "      <td>feel</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>dobj</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feel</td>\n",
       "      <td>feel</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>dobj</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>earth</td>\n",
       "      <td>earth</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text   lemma    pos        dep  is_stop\n",
       "0       The     the    DET        det     True\n",
       "1     world   world   NOUN  nsubjpass    False\n",
       "2        is      be    AUX    auxpass     True\n",
       "3   changed  change   VERB       ROOT    False\n",
       "4         .       .  PUNCT      punct    False\n",
       "5         I       I   PRON      nsubj     True\n",
       "6      feel    feel   VERB       ROOT    False\n",
       "7        it      it   PRON       dobj     True\n",
       "8        in      in    ADP       prep     True\n",
       "9       the     the    DET        det     True\n",
       "10    water   water   NOUN       pobj    False\n",
       "11        .       .  PUNCT      punct    False\n",
       "12        I       I   PRON      nsubj     True\n",
       "13     feel    feel   VERB       ROOT    False\n",
       "14       it      it   PRON       dobj     True\n",
       "15       in      in    ADP       prep     True\n",
       "16      the     the    DET        det     True\n",
       "17    earth   earth   NOUN       pobj    False\n",
       "18        .       .  PUNCT      punct    False\n",
       "19        I       I   PRON      nsubj     True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token-level view\n",
    "tokens = [(t.text, t.lemma_, t.pos_, t.dep_, t.is_stop) for t in doc]\n",
    "pd.DataFrame(tokens, columns=['text','lemma','pos','dep','is_stop']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c38dde",
   "metadata": {},
   "source": [
    "## Batch processing: run metrics on multiple texts and save results\n",
    "Use a loop or list comprehension to compute metrics for a list of documents and concatenate results into a single DataFrame. TextDescriptives will reuse the spaCy model passed to `extract_metrics` if you pass an `nlp` or a model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33381ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos_prop_ADJ</th>\n",
       "      <th>pos_prop_ADP</th>\n",
       "      <th>pos_prop_ADV</th>\n",
       "      <th>pos_prop_AUX</th>\n",
       "      <th>pos_prop_CCONJ</th>\n",
       "      <th>pos_prop_DET</th>\n",
       "      <th>pos_prop_INTJ</th>\n",
       "      <th>pos_prop_NOUN</th>\n",
       "      <th>pos_prop_NUM</th>\n",
       "      <th>...</th>\n",
       "      <th>n_characters</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>smog</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>lix</th>\n",
       "      <th>rix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a short, simple sentence.</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>102.045</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.98000</td>\n",
       "      <td>4.746667</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here is a longer sentence, with more clauses, ...</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>63.695</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>13.06375</td>\n",
       "      <td>15.425000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time, in a land far away, there li...</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>75.765</td>\n",
       "      <td>7.163333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.644444</td>\n",
       "      <td>8.76500</td>\n",
       "      <td>9.015556</td>\n",
       "      <td>40.222222</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pos_prop_ADJ  \\\n",
       "0                  This is a short, simple sentence.      0.250000   \n",
       "1  Here is a longer sentence, with more clauses, ...      0.095238   \n",
       "2  Once upon a time, in a land far away, there li...      0.047619   \n",
       "\n",
       "   pos_prop_ADP  pos_prop_ADV  pos_prop_AUX  pos_prop_CCONJ  pos_prop_DET  \\\n",
       "0      0.000000      0.000000      0.125000        0.000000      0.125000   \n",
       "1      0.047619      0.047619      0.095238        0.047619      0.047619   \n",
       "2      0.047619      0.142857      0.000000        0.000000      0.142857   \n",
       "\n",
       "   pos_prop_INTJ  pos_prop_NOUN  pos_prop_NUM  ...  n_characters  n_sentences  \\\n",
       "0            0.0       0.125000           0.0  ...            28            1   \n",
       "1            0.0       0.238095           0.0  ...            95            1   \n",
       "2            0.0       0.238095           0.0  ...            84            1   \n",
       "\n",
       "   flesch_reading_ease  flesch_kincaid_grade  smog  gunning_fog  \\\n",
       "0              102.045              0.516667   NaN     2.400000   \n",
       "1               63.695              8.350000   NaN    13.900000   \n",
       "2               75.765              7.163333   NaN    11.644444   \n",
       "\n",
       "   automated_readability_index  coleman_liau_index        lix  rix  \n",
       "0                      1.98000            4.746667  22.666667  1.0  \n",
       "1                     13.06375           15.425000  53.500000  6.0  \n",
       "2                      8.76500            9.015556  40.222222  4.0  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'This is a short, simple sentence.',\n",
    "    'Here is a longer sentence, with more clauses, punctuation, and complexity: it should raise reading difficulty.',\n",
    "    'Once upon a time, in a land far away, there lived a programmer who loved natural language processing.'\n",
    "]\n",
    "# extract only readability and pos proportions for speed, or just use None to get all metrics\n",
    "df_batch = pd.concat([td.extract_metrics(text=t, spacy_model='en_core_web_sm', metrics=['readability','pos_proportions']) for t in texts], ignore_index=True)\n",
    "df_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70100a89",
   "metadata": {},
   "source": [
    "## Select specific metrics or components\n",
    "The `metrics` argument accepts a list (e.g., `['readability','descriptive_stats']`) or `None` for all. You can also add only the components you need into a spaCy pipeline: e.g., `nlp.add_pipe('textdescriptives/readability')`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844622f",
   "metadata": {},
   "source": [
    "## some pointers\n",
    "- See the TextDescriptives docs for full API reference and an explanation of each metric: https://hlasse.github.io/TextDescriptives/\n",
    "- If you need multilingual processing, TextDescriptives supports several languages; pass `lang` to `extract_metrics` or load a spaCy model for your target language.\n",
    "- To compute semantic coherence you may want a model with word vectors (e.g., `en_core_web_lg`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e37641",
   "metadata": {},
   "source": [
    "\n",
    "# Some Spacy linguistic features (there are more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9877d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tokens, Lemas, POS, Morphology ===\n",
      "This         | Lema: this         | POS: PRON     | Morphology: Number=Sing|PronType=Dem\n",
      "is           | Lema: be           | POS: AUX      | Morphology: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "a            | Lema: a            | POS: DET      | Morphology: Definite=Ind|PronType=Art\n",
      "short        | Lema: short        | POS: ADJ      | Morphology: Degree=Pos\n",
      ",            | Lema: ,            | POS: PUNCT    | Morphology: PunctType=Comm\n",
      "simple       | Lema: simple       | POS: ADJ      | Morphology: Degree=Pos\n",
      "sentence     | Lema: sentence     | POS: NOUN     | Morphology: Number=Sing\n",
      ".            | Lema: .            | POS: PUNCT    | Morphology: PunctType=Peri\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar el modelo de español\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "\n",
    "doc = nlp(texts[0])\n",
    "\n",
    "print(\"=== Tokens, Lemas, POS, Morphology ===\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:12} | Lema: {token.lemma_:12} | POS: {token.pos_:8} | Morphology: {token.morph}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef3d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dependency Relations ===\n",
      "This       <--nsubj-- is\n",
      "is         <--ROOT-- is\n",
      "a          <--det-- sentence\n",
      "short      <--amod-- sentence\n",
      ",          <--punct-- sentence\n",
      "simple     <--amod-- sentence\n",
      "sentence   <--attr-- is\n",
      ".          <--punct-- is\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Dependency Relations ===\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:10} <--{token.dep_}-- {token.head.text}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
